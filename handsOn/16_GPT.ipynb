{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 16 GPT: Generative Pre-trained Transformer\n",
    "\n",
    "GPT is a model and approach developed by OpenAI. It is primarily known for its capabilities in generating coherent and contextually relevant text over long passages.\n",
    "\n",
    "* Architecture: GPT is based on the Transformer architecture. Unlike some other models that use both an encoder and a decoder, GPT exclusively utilizes the decoder part of the Transformer for its tasks.\n",
    "* Pre-training and Fine-tuning:\n",
    "    - Pre-training: GPT is first pre-trained on a large corpus of text (like books, articles, websites, etc.). During this phase, it learns to predict the next word in a sentence. This process enables the model to learn grammar, facts about the world, reasoning abilities, and even some level of common sense.\n",
    "    - Fine-tuning: After pre-training, the model can be fine-tuned on a specific task, such as translation, question-answering, or summarization, using a smaller, task-specific dataset.\n",
    "\n",
    "* Autoregressive Nature: GPT generates text in an autoregressive manner. This means it produces one word at a time and uses what it's generated so far as a context to generate the next word.\n",
    "\n",
    "#### Key Features:\n",
    "\n",
    "* Generative Abilities: As the name suggests, GPT excels at generating text. It can produce text that is often indistinguishable from what a human might write.\n",
    "* Few-Shot Learning: Introduced with GPT-3, this capability allows the model to perform tasks even when provided with very few examples (sometimes as few as one). By just specifying a task in natural language, GPT-3 can often understand and perform the task without explicit fine-tuning.\n",
    "* Versatility: Unlike many models that are trained for a specific task, GPT models, especially GPT-3, are versatile and can handle a wide range of tasks without task-specific training. This includes writing essays, answering questions, creating poetry, generating code, and much more.\n",
    "\n",
    "#### Versions:\n",
    "\n",
    "* GPT: The original model introduced by OpenAI.\n",
    "\n",
    "* GPT-2: A larger and more powerful version that garnered significant attention due to its impressive text generation capabilities. OpenAI initially withheld the fully-trained model due to concerns about misuse, but later released it given the broader community's responsible usage.\n",
    "\n",
    "* GPT-3: The third iteration with 175 billion parameters, making it one of the largest models ever created. It introduced the concept of few-shot and zero-shot learning, further advancing the state-of-the-art in various NLP tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Exercise: Exploring Creative Writing with GPT\n",
    "\n",
    "Your task is to use OpenAI's GPT model to generate creative content. You'll explore various prompts and settings to see how GPT responds and creates different outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Load GPT-2 Model and Tokenizer. GPT-2 is freely available in Hugging Face's model hub and is still highly effective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "model_name = 'gpt2-medium'  # You can start with 'gpt2' (smaller) and then experiment with larger models\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Generate Creative Content Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_creative_content(prompt, max_length=150, temperature=1.0):\n",
    "    \"\"\"Generate creative content using GPT-2 based on a given prompt.\"\"\"\n",
    "\n",
    "    # Encode the prompt\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
    "\n",
    "    # Generate text\n",
    "    output = model.generate(input_ids, max_length=max_length, temperature=temperature, pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "    # Decode and print the generated text\n",
    "    generated_text = tokenizer.decode(output[:, input_ids.shape[-1]:][0], skip_special_tokens=True)\n",
    "\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Experiment:\n",
    "Use various prompts and observe GPT's creative capabilities.\n",
    "Change parameters like *max_length* and *temperature* to see their impact. (Note: A higher temperature value makes output more random, while a lower value makes it more deterministic.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: Once upon a time, in a kingdom far away,\n",
      " there lived a king who was very fond of his little princess. One day, while the king was out hunting, he was attacked by a wolf. The wolf bit the king's hand, and the king was left with only one hand. The king was very sad, and he went to the forest to pray to the gods for help. The gods told him that he would have to make a new hand from the wolf's paw. The king went to the forest, and he cut off the paw of the wolf. He then made a new hand out of the paw, and he gave it to his little princess. The princess was very happy, and she loved her new hand very much.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Prompt: In a dystopian future, where AI rules the world,\n",
      " a young woman named Aiden Pearce is sent to a remote island to be trained as a killer. But when she arrives, she finds herself in the middle of a battle between the machines and the humans.\n",
      "\n",
      "The film is directed by Neill Blomkamp, who also wrote the screenplay.\n",
      "\n",
      "The film is set to be released on October 6, 2018.\n",
      "\n",
      "The film is also set to be released on October 6, 2018.\n",
      "\n",
      "The film is also set to be released on October 6, 2018.\n",
      "\n",
      "The film is also set to be released on October 6, 2018.\n",
      "\n",
      "The film is also set to be released on October 6, 2018.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Prompt: The last dinosaur on Earth was not like the others. It\n",
      " was a giant, lumbering, carnivorous dinosaur that lived in the Cretaceous Period, about 100 million years ago. It was a carnivore that ate everything from small mammals to large dinosaurs.\n",
      "\n",
      "The dinosaur was named the Argentinosaurus, after the Argentinian province where it was found.\n",
      "\n",
      "The dinosaur was discovered in the fossil-rich rock of the Cerro Ballena Formation in northern Argentina.\n",
      "\n",
      "The dinosaur was about the size of a modern-day horse, and it had a long, narrow snout and a long, narrow tail.\n",
      "\n",
      "The dinosaur was about the size of a modern-day horse, and it had a long, narrow sn\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Prompt: Deep beneath the ocean waves, a secret civilization\n",
      " of aliens has been hiding for centuries. They have built a vast network of underground cities, and they are preparing to unleash a devastating attack on Earth.\n",
      "\n",
      "The aliens have built a vast network of underground cities, and they are preparing to unleash a devastating attack on Earth.\n",
      "\n",
      "The aliens have built a vast network of underground cities, and they are preparing to unleash a devastating attack on Earth.\n",
      "\n",
      "The aliens have built a vast network of underground cities, and they are preparing to unleash a devastating attack on Earth.\n",
      "\n",
      "The aliens have built a vast network of underground cities, and they are preparing to unleash a devastating attack on Earth.\n",
      "\n",
      "The aliens have built a vast network of underground\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    \"Once upon a time, in a kingdom far away,\",\n",
    "    \"In a dystopian future, where AI rules the world,\",\n",
    "    \"The last dinosaur on Earth was not like the others. It\",\n",
    "    \"Deep beneath the ocean waves, a secret civilization\"\n",
    "]\n",
    "\n",
    "for prompt in prompts:\n",
    "    print(f\"Prompt: {prompt}\")\n",
    "    print(generate_creative_content(prompt))\n",
    "    print(\"\\n\" + \"-\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Discussion and Analysis:\n",
    "- Analyze the quality of the generated text: coherence, relevancy, and creativity.\n",
    "- Discuss how different prompts influence the direction of the story.\n",
    "- Experiment with custom prompts to generate different genres of creative content (e.g., horror, sci-fi, romance)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Tasks:\n",
    "* Use a larger GPT-2 variant (gpt2-large or gpt2-xl) and compare the quality of outputs.\n",
    "* Incorporate user feedback loops, where after getting an initial piece of text, they can provide a follow-up prompt to continue or steer the story."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'gpt2-large'  # You can start with 'gpt2' (smaller) and then experiment with larger models\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_creative_content(prompt, max_length=150, temperature=1.0):\n",
    "    \"\"\"Generate creative content using GPT-2 based on a given prompt.\"\"\"\n",
    "\n",
    "    # Encode the prompt\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
    "\n",
    "    # Generate text\n",
    "    output = model.generate(input_ids, max_length=max_length, temperature=temperature, pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "    # Decode and print the generated text\n",
    "    generated_text = tokenizer.decode(output[:, input_ids.shape[-1]:][0], skip_special_tokens=True)\n",
    "\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: Once upon a time, in a kingdom far away,\n",
      " the king and queen were blessed with a beautiful baby girl. Ever since that day, the princess has been growing up in a world of magic and adventure. But one day, the king and queen are kidnapped by a band of thieves. Now, the princess must find her way home and save her kingdom.\n",
      "\n",
      "The game is set in a fantasy world where the player controls a young girl named Princess Zelda. The game is set in a fantasy world where the player controls a young girl named Princess Zelda. The game is set in a fantasy world where the player controls a young girl named Princess Zelda. The game is set in a fantasy world where the player controls a young girl named Princess Zelda.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Prompt: In a dystopian future, where AI rules the world,\n",
      " the only way to survive is to become a super-soldier.\n",
      "\n",
      "The game is set in a future where the world is ruled by a super-intelligence called the AI. The AI is a powerful and intelligent being that has been created by the government to protect the world from the threat of a super-intelligence.\n",
      "\n",
      "The game is set in a dystopian future where the world is ruled by a super-intelligence called the AI. The AI is a powerful and intelligent being that has been created by the government to protect the world from the threat of a super-intelligence.\n",
      "\n",
      "The game is set in a dystopian future where the world is ruled by a super-intelligence called the\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Prompt: The last dinosaur on Earth was not like the others. It\n",
      " was a giant, long-necked, long-necked, long-necked, long-necked, long-necked, long-necked, long-necked, long-necked, long-necked, long-necked, long-necked, long-necked, long-necked, long-necked, long-necked, long-necked, long-necked, long-necked, long-necked, long-necked, long-necked, long-necked, long-necked, long-necked, long-necked, long-necked, long-necked\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Prompt: Deep beneath the ocean waves, a secret civilization\n",
      " has been building a massive, underground city. The city is called the City of the Dead, and it is home to a mysterious race of undead. The city is a living, breathing, breathing city, and it is the only place in the world where the dead can live. The City of the Dead is a living, breathing, breathing city. It is a living, breathing, breathing city. It is a living, breathing, breathing city. It is a living, breathing, breathing city. It is a living, breathing, breathing city. It is a living, breathing, breathing city. It is a living, breathing, breathing city. It is a living, breathing, breathing city. It\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    \"Once upon a time, in a kingdom far away,\",\n",
    "    \"In a dystopian future, where AI rules the world,\",\n",
    "    \"The last dinosaur on Earth was not like the others. It\",\n",
    "    \"Deep beneath the ocean waves, a secret civilization\"\n",
    "]\n",
    "\n",
    "for prompt in prompts:\n",
    "    print(f\"Prompt: {prompt}\")\n",
    "    print(generate_creative_content(prompt))\n",
    "    print(\"\\n\" + \"-\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "517dff33494b44639aac249650e4b0c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/689 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marcos\\miniconda3\\envs\\tf2\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Marcos\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5b1659c6eda469781a0c51cd2135b62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/6.43G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ddaf9691feb4f2f830333f051101e49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81a754e754bc471a829e63b36eae0540",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaee609f1d634c59b3a60c99d9099cc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = 'gpt2-xl'  # You can start with 'gpt2' (smaller) and then experiment with larger models\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_creative_content(prompt, max_length=150, temperature=1.0):\n",
    "    \"\"\"Generate creative content using GPT-2 based on a given prompt.\"\"\"\n",
    "\n",
    "    # Encode the prompt\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
    "\n",
    "    # Generate text\n",
    "    output = model.generate(input_ids, max_length=max_length, temperature=temperature, pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "    # Decode and print the generated text\n",
    "    generated_text = tokenizer.decode(output[:, input_ids.shape[-1]:][0], skip_special_tokens=True)\n",
    "\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: Once upon a time, in a kingdom far away,\n",
      " there lived a king who was very fond of his little princess. One day, while the king was out hunting, he was attacked by a wolf. The wolf bit the king's hand, and the king was left with only one hand. The king was very sad, and he went to the forest to pray to the gods for help. The gods told him that he would have to make a new hand from the wolf's paw. The king went to the forest, and he cut off the paw of the wolf. He then made a new hand out of the paw, and he gave it to his little princess. The princess was very happy, and she loved her new hand very much.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Prompt: In a dystopian future, where AI rules the world,\n",
      " a young woman named Aiden Pearce is sent to a remote island to be trained as a killer. But when she arrives, she finds herself in the middle of a battle between the machines and the humans.\n",
      "\n",
      "The film is directed by Neill Blomkamp, who also wrote the screenplay.\n",
      "\n",
      "The film is set to be released on October 6, 2018.\n",
      "\n",
      "The film is also set to be released on October 6, 2018.\n",
      "\n",
      "The film is also set to be released on October 6, 2018.\n",
      "\n",
      "The film is also set to be released on October 6, 2018.\n",
      "\n",
      "The film is also set to be released on October 6, 2018.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Prompt: The last dinosaur on Earth was not like the others. It\n",
      " was a giant, lumbering, carnivorous dinosaur that lived in the Cretaceous Period, about 100 million years ago. It was a carnivore that ate everything from small mammals to large dinosaurs.\n",
      "\n",
      "The dinosaur was named the Argentinosaurus, after the Argentinian province where it was found.\n",
      "\n",
      "The dinosaur was discovered in the fossil-rich rock of the Cerro Ballena Formation in northern Argentina.\n",
      "\n",
      "The dinosaur was about the size of a modern-day horse, and it had a long, narrow snout and a long, narrow tail.\n",
      "\n",
      "The dinosaur was about the size of a modern-day horse, and it had a long, narrow sn\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Prompt: Deep beneath the ocean waves, a secret civilization\n",
      " of aliens has been hiding for centuries. They have built a vast network of underground cities, and they are preparing to unleash a devastating attack on Earth.\n",
      "\n",
      "The aliens have built a vast network of underground cities, and they are preparing to unleash a devastating attack on Earth.\n",
      "\n",
      "The aliens have built a vast network of underground cities, and they are preparing to unleash a devastating attack on Earth.\n",
      "\n",
      "The aliens have built a vast network of underground cities, and they are preparing to unleash a devastating attack on Earth.\n",
      "\n",
      "The aliens have built a vast network of underground cities, and they are preparing to unleash a devastating attack on Earth.\n",
      "\n",
      "The aliens have built a vast network of underground\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    \"Once upon a time, in a kingdom far away,\",\n",
    "    \"In a dystopian future, where AI rules the world,\",\n",
    "    \"The last dinosaur on Earth was not like the others. It\",\n",
    "    \"Deep beneath the ocean waves, a secret civilization\"\n",
    "]\n",
    "\n",
    "for prompt in prompts:\n",
    "    print(f\"Prompt: {prompt}\")\n",
    "    print(generate_creative_content(prompt))\n",
    "    print(\"\\n\" + \"-\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have notice through we increase the complexibility of GPT model the runtime to give us the answer to the prompt increase and the output in each case is \n",
    "a little more realistic, but something happens with the In a dystopian future prompt because the model isn't able to give us a logical output, just repeat sometimes the same output. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
